{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the YAML configuration file\n",
    "yaml_file_path = 'feature_store/config_v1.yaml'\n",
    "\n",
    "# Write the configuration data to a YAML file\n",
    "with open(yaml_file_path, 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Features\n",
    "from scripts import feature_store\n",
    "X_train = feature_store.fetch_data_from_store(yaml_file_path = yaml_file_path)\n",
    "X_train = X_train.head(-7) # save some rows for later\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get targets\n",
    "from scripts import feature_processing\n",
    "\n",
    "csv_file_path = 'data/energy_data_new.csv'\n",
    "df = pd.read_csv(csv_file_path, parse_dates=['period'])\n",
    "df.set_index('period', inplace=True)\n",
    "\n",
    "targets_df = feature_processing.get_targets(df)\n",
    "targets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store.update_feature_store(targets_df, yaml_file_path, targets = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_store.fetch_data_from_store(X_train.index.min(), yaml_file_path, targets = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same date range for targes and features\n",
    "Y_train = feature_store.fetch_data_from_store(X_train.index.min(), yaml_file_path, targets = True)[:X_train.index.max()]\n",
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn into a list\n",
    "y_train_ls= []\n",
    "for target in Y_train.columns:\n",
    "  y_train_ls.append(Y_train[target])\n",
    "\n",
    "y_train_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use XGB to train a model on the features, given the target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Loop through targets - train one model for each target variable\n",
    "cv_results_ls = []\n",
    "for y_train in y_train_ls:\n",
    "\n",
    "  # Prepare the DMatrix which is required by XGBoost\n",
    "  dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "\n",
    "  # Define XGBoost parameters\n",
    "  params = {\n",
    "    #'max_depth': 6,\n",
    "    #'min_child_weight': 1,\n",
    "    #'eta': 0.5,\n",
    "    #'subsample': 1,\n",
    "    #'colsample_bytree': 1,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "  }\n",
    "\n",
    "  # Perform cross-validation\n",
    "  cv_results = xgb.cv(\n",
    "      params=params,\n",
    "      dtrain=dtrain,\n",
    "      num_boost_round=100,\n",
    "      nfold = 4,\n",
    "      early_stopping_rounds=10,\n",
    "      metrics='rmse',\n",
    "      as_pandas=True,\n",
    "      seed=123\n",
    "  )\n",
    "  cv_results_ls.append(cv_results)\n",
    "  # Show the last mean RMSE as a measure of final performance\n",
    "  print(f\"Last mean RMSE: {cv_results['test-rmse-mean'][-1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand when the early stopping kicked in and get the best number of boosting rounds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot RMSE through iterations with different colors for each line\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for idx, cv_results in enumerate(cv_results_ls):\n",
    "    plt.plot(cv_results['test-rmse-mean'], label=f'CV Run {idx+1}')\n",
    "\n",
    "plt.title('Test RMSE Through Iterations')\n",
    "plt.xlabel('Number of Boosting Rounds')\n",
    "plt.ylabel('Mean RMSE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Retrain the models with the best parameters (here: just boosting rounds) on full training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the final models\n",
    "final_models_ls = []\n",
    "\n",
    "# Use the same params here you used in cross-validation\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "  }\n",
    "\n",
    "# Iterate through each set of cross-validation results and corresponding training targets\n",
    "for cv_results, y_train in zip(cv_results_ls, y_train_ls):\n",
    "    # Determine the optimal number of boosting rounds from cross-validation results\n",
    "    optimal_boost_rounds = cv_results['test-rmse-mean'].idxmin() + 1\n",
    "\n",
    "    # Initialize the XGBoost regressor with determined parameters\n",
    "    final_model = xgb.XGBRegressor(\n",
    "        n_estimators=optimal_boost_rounds,\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    # Train the model on the full training dataset\n",
    "    final_model.fit(X_train, y_train)\n",
    "\n",
    "    # Append the trained model to the list\n",
    "    final_models_ls.append(final_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Understand model performance by looking at in-sample residuals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate residual plot\n",
    "\n",
    "# Initialize lists to hold all predicted values and residuals\n",
    "all_y_pred = []\n",
    "all_residuals = []\n",
    "\n",
    "# Generate a list of colors using a colormap\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, len(final_models_ls)))\n",
    "\n",
    "# Plot residuals for each model\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for idx, (final_model, y_train) in enumerate(zip(final_models_ls, y_train_ls)):\n",
    "    # Make predictions\n",
    "    y_pred = final_model.predict(X_train)\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals = y_train - y_pred\n",
    "\n",
    "    # Plot residuals with a unique color for each model\n",
    "    plt.scatter(y_pred, residuals, color=colors[idx], alpha=0.5, label=f'Model {idx+1}')\n",
    "\n",
    "# Add plot title and labels\n",
    "plt.axhline(y=0, color='red', linestyle='--')\n",
    "plt.title('In-Sample Residual Plot for All Models')\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Residuals')\n",
    "plt.legend()  # Add a legend to differentiate each model\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Export the models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save each model with a unique filename\n",
    "for idx, final_model in enumerate(final_models_ls):\n",
    "    filename = f'models/batch_demand_forecaster_model_{idx+1}.pkl'  # Create a unique filename for each model\n",
    "    joblib.dump(final_model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
