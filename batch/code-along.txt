import pandas as pd
import time
import yaml

# Load offset from yaml
yaml_file_path = 'feature_store/config_v1.yaml'
with open(yaml_file_path, 'r') as file:
    config = yaml.safe_load(file)
max_offset_days = int(config['feature_store']['feature_offset'])
max_offset_hours = (max_offset_days + 1) * 24 

# Measure time to read data
start_time = time.time()

datetime = "2024-04-03 10:00:00"
csv_file_path = 'data/energy_data_new.csv'

# This could also be a SQL statement
mini_batch_df = (pd.read_csv(csv_file_path, parse_dates=['period'])
      .set_index('period')
      .sort_index(ascending=False)
      .query("period <= @datetime"))[:max_offset_hours]

elapsed_time = time.time() - start_time

print(f"Time to read data: {elapsed_time:.3f} seconds")

---

start_time = time.time()

from scripts import feature_processing

feature_processing.feature_pipeline_online(mini_batch_df)

elapsed_time = time.time() - start_time

print(f"Time to process batch: {elapsed_time:.3f} seconds")

---

