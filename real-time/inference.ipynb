{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realtime inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a Kafka consumer to subscribe to messages in the feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer\n",
    "import json\n",
    "\n",
    "def fetch_all_feature_records():\n",
    "    # Kafka Consumer configuration for reading from the beginning of the topic\n",
    "    conf = {\n",
    "        'bootstrap.servers': \"localhost:9092\",\n",
    "        'group.id': \"feature_store_reader\",\n",
    "        'auto.offset.reset': 'latest'\n",
    "        }\n",
    "\n",
    "    # Initialize Kafka Consumer and subscribe to the topic\n",
    "    consumer = Consumer(conf)\n",
    "    consumer.subscribe(['feature_store'])\n",
    "\n",
    "    feature_records = []  # List to store feature data\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            msg = consumer.poll(1.0)  # Poll for messages with a 1-second timeout\n",
    "            if msg is None:\n",
    "                break  # Exit loop if no more messages\n",
    "            if not msg.error():\n",
    "                # Convert message from JSON and add to list\n",
    "                feature_records.append(json.loads(msg.value().decode('utf-8')))\n",
    "            else:\n",
    "                break  # Exit loop on error\n",
    "    finally:\n",
    "        consumer.close()  # Clean up: close consumer\n",
    "\n",
    "    return feature_records  # Return the collected feature records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the available messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "features_df = pd.DataFrame(fetch_all_feature_records())\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the latest complete feature record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_feature_record = features_df.groupby('id').first().dropna().sort_index(ascending=False)[:1]\n",
    "latest_feature_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get predictions for this record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and run prediction\n",
    "import joblib\n",
    "def load_model(model_path):\n",
    "  model = joblib.load(model_path)\n",
    "  return model\n",
    "\n",
    "model = load_model(\"models/energy_demand_model_v4.pkl\")\n",
    "feature_names = ['lag_1', 'lag_2', 'lag_6', 'lag_12', 'lag_24', 'rolling_mean_7', 'rolling_std_7', 'hour', 'day_of_week', 'month', 'temperature_forecast']\n",
    "latest_feature_record = latest_feature_record[feature_names]\n",
    "model.predict(latest_feature_record)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
